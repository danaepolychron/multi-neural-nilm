{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "767e00e6",
   "metadata": {},
   "source": [
    "# Setting up an Experiment Baseline Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1951760",
   "metadata": {},
   "source": [
    "This serves as a baseline framework for the multi-label neural NILM experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b32ecb0",
   "metadata": {},
   "source": [
    "### Import Python Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b097dcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from data import Environment, get_on_off\n",
    "from data.generator import Seq2Seq, Seq2Point \n",
    "\n",
    "from models import FCN, ResNet, ConvGRU, ConvLSTM, FCN_AE\n",
    "\n",
    "from experiments import Experiment\n",
    "from experiments.metrics import validation_report, evaluation_report, confusion_matrix_report, roc_report\n",
    "\n",
    "from utils.path_finder import NILMTK_SOURCE, SCENARIOS, SOURCES, PRETRAINED, RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c06e6208",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd49817",
   "metadata": {},
   "source": [
    "### Setup the Experiment Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c469a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCENARIO = 4\n",
    "BATCH_SIZE = 32\n",
    "WINDOW_SIZE = 100\n",
    "EPOCHS = 1\n",
    "LRN_RATE = 0.0001\n",
    "SPEED = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5ce58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSIFIERS = {\"FCN\": FCN(1,3), \n",
    "               \"ResNet\": ResNet(1,3), \n",
    "               \"ConvGRU\": ConvGRU(1,3), \n",
    "               \"ConvLSTM\": ConvLSTM(1,3), \n",
    "               \"FCN_AE\":FCN_AE(1,3)\n",
    "              }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5e7c8a",
   "metadata": {},
   "source": [
    "### Run the Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7835d3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = Experiment(scenario=SCENARIO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59b90b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, clf in CLASSIFIERS.items():\n",
    "\n",
    "    experiment.setup_running_params(model=clf, epochs=EPOCHS, window=WINDOW_SIZE, batch_size=BATCH_SIZE, lrn_rate=LRN_RATE, speed=SPEED)\n",
    "    experiment.run(cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3084aa45",
   "metadata": {},
   "source": [
    "### Evaluate Experiment Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23961832",
   "metadata": {},
   "outputs": [],
   "source": [
    "measures = ['fridge', 'dish washer', 'washer dryer', 'macro']  \n",
    "metric = \"F1 Score\" \n",
    "\n",
    "target_results = {}\n",
    "model_results = {}\n",
    "\n",
    "for name in CLASSIFIERS.keys():\n",
    "    \n",
    "    target_filename = os.path.join(RESULTS, \"scenario-{}/{}/{}-min-target-results.csv\".format(experiment.scenario, name, experiment.window))\n",
    "    target_results[name] = pd.read_csv(target_filename, index_col=0)\n",
    "\n",
    "    model_filename = os.path.join(RESULTS, \"scenario-{}/{}/{}-min-model-results.csv\".format(experiment.scenario, name, experiment.window))\n",
    "    model_results[name] = pd.read_csv(model_filename, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f889398",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}\n",
    "\n",
    "for i in measures:\n",
    "    \n",
    "    scores[i] = {}\n",
    "    for name in CLASSIFIERS.keys():\n",
    "        \n",
    "        \n",
    "        if i == \"macro\":\n",
    "            scores[i][name] = model_results[name].loc[i, metric]\n",
    "        else:\n",
    "            scores[i][name] = target_results[name].loc[i, metric]\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(ml-nilm-env)",
   "language": "python",
   "name": "ml-nilm-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
